{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-6409bbb4abe4>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-6409bbb4abe4>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    np.load \"C:\\Users\\Thais Erbas\\matesp\\python-1-carlosjessicathais2\\dados\\brazil-TAVG-Trend.txt\"\u001b[0m\n\u001b[1;37m                                                                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "np.load \"C:\\Users\\Thais Erbas\\matesp\\python-1-carlosjessicathais2\\dados\\brazil-TAVG-Trend.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load in module numpy.lib.npyio:\n",
      "\n",
      "load(file, mmap_mode=None, allow_pickle=True, fix_imports=True, encoding='ASCII')\n",
      "    Load arrays or pickled objects from ``.npy``, ``.npz`` or pickled files.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    file : file-like object or string\n",
      "        The file to read. File-like objects must support the\n",
      "        ``seek()`` and ``read()`` methods. Pickled files require that the\n",
      "        file-like object support the ``readline()`` method as well.\n",
      "    mmap_mode : {None, 'r+', 'r', 'w+', 'c'}, optional\n",
      "        If not None, then memory-map the file, using the given mode (see\n",
      "        `numpy.memmap` for a detailed description of the modes).  A\n",
      "        memory-mapped array is kept on disk. However, it can be accessed\n",
      "        and sliced like any ndarray.  Memory mapping is especially useful\n",
      "        for accessing small fragments of large files without reading the\n",
      "        entire file into memory.\n",
      "    allow_pickle : bool, optional\n",
      "        Allow loading pickled object arrays stored in npy files. Reasons for\n",
      "        disallowing pickles include security, as loading pickled data can\n",
      "        execute arbitrary code. If pickles are disallowed, loading object\n",
      "        arrays will fail.\n",
      "        Default: True\n",
      "    fix_imports : bool, optional\n",
      "        Only useful when loading Python 2 generated pickled files on Python 3,\n",
      "        which includes npy/npz files containing object arrays. If `fix_imports`\n",
      "        is True, pickle will try to map the old Python 2 names to the new names\n",
      "        used in Python 3.\n",
      "    encoding : str, optional\n",
      "        What encoding to use when reading Python 2 strings. Only useful when\n",
      "        loading Python 2 generated pickled files on Python 3, which includes\n",
      "        npy/npz files containing object arrays. Values other than 'latin1',\n",
      "        'ASCII', and 'bytes' are not allowed, as they can corrupt numerical\n",
      "        data. Default: 'ASCII'\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    result : array, tuple, dict, etc.\n",
      "        Data stored in the file. For ``.npz`` files, the returned instance\n",
      "        of NpzFile class must be closed to avoid leaking file descriptors.\n",
      "    \n",
      "    Raises\n",
      "    ------\n",
      "    IOError\n",
      "        If the input file does not exist or cannot be read.\n",
      "    ValueError\n",
      "        The file contains an object array, but allow_pickle=False given.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    save, savez, savez_compressed, loadtxt\n",
      "    memmap : Create a memory-map to an array stored in a file on disk.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    - If the file contains pickle data, then whatever object is stored\n",
      "      in the pickle is returned.\n",
      "    - If the file is a ``.npy`` file, then a single array is returned.\n",
      "    - If the file is a ``.npz`` file, then a dictionary-like object is\n",
      "      returned, containing ``{filename: array}`` key-value pairs, one for\n",
      "      each file in the archive.\n",
      "    - If the file is a ``.npz`` file, the returned value supports the\n",
      "      context manager protocol in a similar fashion to the open function::\n",
      "    \n",
      "        with load('foo.npz') as data:\n",
      "            a = data['a']\n",
      "    \n",
      "      The underlying file descriptor is closed when exiting the 'with'\n",
      "      block.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Store data to disk, and load it again:\n",
      "    \n",
      "    >>> np.save('/tmp/123', np.array([[1, 2, 3], [4, 5, 6]]))\n",
      "    >>> np.load('/tmp/123.npy')\n",
      "    array([[1, 2, 3],\n",
      "           [4, 5, 6]])\n",
      "    \n",
      "    Store compressed data to disk, and load it again:\n",
      "    \n",
      "    >>> a=np.array([[1, 2, 3], [4, 5, 6]])\n",
      "    >>> b=np.array([1, 2])\n",
      "    >>> np.savez('/tmp/123.npz', a=a, b=b)\n",
      "    >>> data = np.load('/tmp/123.npz')\n",
      "    >>> data['a']\n",
      "    array([[1, 2, 3],\n",
      "           [4, 5, 6]])\n",
      "    >>> data['b']\n",
      "    array([1, 2])\n",
      "    >>> data.close()\n",
      "    \n",
      "    Mem-map the stored array, and then access the second row\n",
      "    directly from disk:\n",
      "    \n",
      "    >>> X = np.load('/tmp/123.npy', mmap_mode='r')\n",
      "    >>> X[1, :]\n",
      "    memmap([4, 5, 6])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Failed to interpret file 'dados/brazil-TAVG-Trend.txt' as a pickle",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Thais Erbas\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    412\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    414\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: invalid load key, '%'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e12f0a31faf4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"dados/brazil-TAVG-Trend.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Thais Erbas\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    414\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m                 raise IOError(\n\u001b[1;32m--> 416\u001b[1;33m                     \"Failed to interpret file %s as a pickle\" % repr(file))\n\u001b[0m\u001b[0;32m    417\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mown_fid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Failed to interpret file 'dados/brazil-TAVG-Trend.txt' as a pickle"
     ]
    }
   ],
   "source": [
    "np.load (\"dados/brazil-TAVG-Trend.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Failed to interpret file 'dados/brazil-TAVG-Trend.txt' as a pickle",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Thais Erbas\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    412\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    414\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: invalid load key, '%'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-b3b7bd26b378>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dados/brazil-TAVG-Trend.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Thais Erbas\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    414\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m                 raise IOError(\n\u001b[1;32m--> 416\u001b[1;33m                     \"Failed to interpret file %s as a pickle\" % repr(file))\n\u001b[0m\u001b[0;32m    417\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mown_fid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Failed to interpret file 'dados/brazil-TAVG-Trend.txt' as a pickle"
     ]
    }
   ],
   "source": [
    "np.load('dados/brazil-TAVG-Trend.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dados= np.loadtxt('dados/brazil-TAVG-Trend.txt', comments='%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ano= dados[:,0]\n",
    "mes= \n",
    "anomalia_anual="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.83200000e+03   1.00000000e+00  -5.75000000e-01 ...,              nan\n",
      "               nan              nan]\n",
      " [  1.83200000e+03   2.00000000e+00  -1.00500000e+00 ...,              nan\n",
      "               nan              nan]\n",
      " [  1.83200000e+03   3.00000000e+00  -7.93000000e-01 ...,              nan\n",
      "               nan              nan]\n",
      " ..., \n",
      " [  2.01300000e+03   7.00000000e+00   7.72000000e-01 ...,              nan\n",
      "               nan              nan]\n",
      " [  2.01300000e+03   8.00000000e+00   1.86000000e-01 ...,              nan\n",
      "               nan              nan]\n",
      " [  2.01300000e+03   9.00000000e+00              nan ...,              nan\n",
      "               nan              nan]]\n"
     ]
    }
   ],
   "source": [
    "print (dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function array in module numpy.core.multiarray:\n",
      "\n",
      "array(...)\n",
      "    array(object, dtype=None, copy=True, order=None, subok=False, ndmin=0)\n",
      "    \n",
      "    Create an array.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    object : array_like\n",
      "        An array, any object exposing the array interface, an\n",
      "        object whose __array__ method returns an array, or any\n",
      "        (nested) sequence.\n",
      "    dtype : data-type, optional\n",
      "        The desired data-type for the array.  If not given, then\n",
      "        the type will be determined as the minimum type required\n",
      "        to hold the objects in the sequence.  This argument can only\n",
      "        be used to 'upcast' the array.  For downcasting, use the\n",
      "        .astype(t) method.\n",
      "    copy : bool, optional\n",
      "        If true (default), then the object is copied.  Otherwise, a copy\n",
      "        will only be made if __array__ returns a copy, if obj is a\n",
      "        nested sequence, or if a copy is needed to satisfy any of the other\n",
      "        requirements (`dtype`, `order`, etc.).\n",
      "    order : {'C', 'F', 'A'}, optional\n",
      "        Specify the order of the array.  If order is 'C', then the array\n",
      "        will be in C-contiguous order (last-index varies the fastest).\n",
      "        If order is 'F', then the returned array will be in\n",
      "        Fortran-contiguous order (first-index varies the fastest).\n",
      "        If order is 'A' (default), then the returned array may be\n",
      "        in any order (either C-, Fortran-contiguous, or even discontiguous),\n",
      "        unless a copy is required, in which case it will be C-contiguous.\n",
      "    subok : bool, optional\n",
      "        If True, then sub-classes will be passed-through, otherwise\n",
      "        the returned array will be forced to be a base-class array (default).\n",
      "    ndmin : int, optional\n",
      "        Specifies the minimum number of dimensions that the resulting\n",
      "        array should have.  Ones will be pre-pended to the shape as\n",
      "        needed to meet this requirement.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        An array object satisfying the specified requirements.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    empty, empty_like, zeros, zeros_like, ones, ones_like, fill\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.array([1, 2, 3])\n",
      "    array([1, 2, 3])\n",
      "    \n",
      "    Upcasting:\n",
      "    \n",
      "    >>> np.array([1, 2, 3.0])\n",
      "    array([ 1.,  2.,  3.])\n",
      "    \n",
      "    More than one dimension:\n",
      "    \n",
      "    >>> np.array([[1, 2], [3, 4]])\n",
      "    array([[1, 2],\n",
      "           [3, 4]])\n",
      "    \n",
      "    Minimum dimensions 2:\n",
      "    \n",
      "    >>> np.array([1, 2, 3], ndmin=2)\n",
      "    array([[1, 2, 3]])\n",
      "    \n",
      "    Type provided:\n",
      "    \n",
      "    >>> np.array([1, 2, 3], dtype=complex)\n",
      "    array([ 1.+0.j,  2.+0.j,  3.+0.j])\n",
      "    \n",
      "    Data-type consisting of more than one element:\n",
      "    \n",
      "    >>> x = np.array([(1,2),(3,4)],dtype=[('a','<i4'),('b','<i4')])\n",
      "    >>> x['a']\n",
      "    array([1, 3])\n",
      "    \n",
      "    Creating an array from sub-classes:\n",
      "    \n",
      "    >>> np.array(np.mat('1 2; 3 4'))\n",
      "    array([[1, 2],\n",
      "           [3, 4]])\n",
      "    \n",
      "    >>> np.array(np.mat('1 2; 3 4'), subok=True)\n",
      "    matrix([[1, 2],\n",
      "            [3, 4]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-678744264002>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdados\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "np.read(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.83200000e+03   1.00000000e+00  -5.75000000e-01 ...,              nan\n",
      "               nan              nan]\n",
      " [  1.83200000e+03   2.00000000e+00  -1.00500000e+00 ...,              nan\n",
      "               nan              nan]\n",
      " [  1.83200000e+03   3.00000000e+00  -7.93000000e-01 ...,              nan\n",
      "               nan              nan]\n",
      " ..., \n",
      " [  2.01300000e+03   7.00000000e+00   7.72000000e-01 ...,              nan\n",
      "               nan              nan]\n",
      " [  2.01300000e+03   8.00000000e+00   1.86000000e-01 ...,              nan\n",
      "               nan              nan]\n",
      " [  2.01300000e+03   9.00000000e+00              nan ...,              nan\n",
      "               nan              nan]]\n"
     ]
    }
   ],
   "source": [
    "print(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
